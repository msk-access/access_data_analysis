from pathlib import Path
from typing import List, Optional
import typer
import pandas as pd


def main(
    list_of_files: Path = typer.Option(
        "",
        "--list",
        "-l",
        help="File of files, List of CSV files to be converted to maf, one per line, no header, CSV file generated by Rscript filter_calls.R",
    ),
    csv: Optional[List[Path]] = typer.Option(
        "",
        "--csv",
        "-i",
        exists=True,
        file_okay=True,
        dir_okay=False,
        writable=False,
        readable=True,
        resolve_path=True,
        help="File to convert from csv to maf. CSV file generated by Rscript filter_calls.R, Can be given multiple times",
    ),
    normal: bool = typer.Option(
        False,
        "--normal/--keep-normal",
        "-n/-N",
        help="Keep samples tagged as normal",
    ),
    output_file_prefix: str = typer.Option(
        "csv_to_maf_output",
        "--prefix",
        "-p",
        help="Prefix of the output MAF and EXCEL file",
    ),
):

    """
    Tool does the following operations:

    A. Read one or more files from the inputs

    B. Removes unwanted columns, modifying the column headers depending on the requirements

    C. Massaging the data frame to make it compatible with MAF format

    D. Write the data frame to a file in MAF format and Excel format

    Requirement:
    pandas; openpyxl; typing; typer;

    """
    if not list_of_files:
        typer.secho(
            "File are not provided as file of files.", fg=typer.colors.BRIGHT_YELLOW
        )
        if not csv:
            typer.secho(
                "File were not provided via command line as well",
                fg=typer.colors.BRIGHT_RED,
            )
            raise typer.Abort()

    # Read file of files
    if not csv:
        csv = [line.strip() for line in open(list_of_files, "r")]
    # print(csv)
    final_df = pd.DataFrame()
    for csv_file in csv:
        if Path(csv_file).is_file():
            # Read csv file
            typer.secho(f"Reading: {csv_file}", fg=typer.colors.BRIGHT_GREEN)
            csv_df = pd.read_csv(csv_file, sep=",", low_memory=False)
            # filter csv of "duplex.called columns"
            csv_df = csv_df.loc[:, ~csv_df.columns.str.contains("__duplex.called")]
            # filter csv of "duplex_support_num columns"
            csv_df = csv_df.loc[:, ~csv_df.columns.str.contains("duplex_support_num")]
            # filter csv of "normal" samples if normal is not wanted
            if not normal:
                csv_df = csv_df.loc[:, ~csv_df.columns.str.contains("normal")]
            # filter rows that have call_confidence == "Drop"
            csv_df = csv_df[
                csv_df["call_confidence"]
                .astype(str)
                .str.lower()
                .str.contains("drop", na=False)
                == False
            ]
            is_csv_df_empty = csv_df.empty
            # melt the data frame
            if is_csv_df_empty == False:
                melt_csv_df = csv_df.melt(
                    id_vars=[
                        "Hugo_Symbol",
                        "Chromosome",
                        "Start_Position",
                        "End_Position",
                        "Variant_Classification",
                        "HGVSp_Short",
                        "Reference_Allele",
                        "Tumor_Seq_Allele2",
                        "ExAC_AF",
                        "Hotspot",
                        "DMP",
                        "CH",
                        "call_confidence",
                    ],
                    var_name="Tumor_Sample_Barcode",
                    value_name="Evidence",
                )
                # fix tumor_sample_barcode
                melt_csv_df[
                    "Tumor_Sample_Barcode"
                ] = melt_csv_df.Tumor_Sample_Barcode.str.split("___", 1).str.get(0)
                # convert Chromosome to string
                melt_csv_df["Chromosome"] = melt_csv_df["Chromosome"].astype(str)
                # split Evidence columns into multiple columns
                melt_csv_df[["t_alt_count", "t_depth"]] = melt_csv_df[
                    "Evidence"
                ].str.split("/", 1, expand=True)
                # convert t_alt_count to to_numeric
                melt_csv_df["t_alt_count"] = melt_csv_df["t_alt_count"].apply(
                    pd.to_numeric, errors="coerce"
                )
                # remove variant frequency information
                melt_csv_df["t_depth"] = melt_csv_df.t_depth.str.split("(", 1).str.get(
                    0
                )
                # convert t_depth to to_numeric
                melt_csv_df["t_depth"] = melt_csv_df["t_depth"].apply(
                    pd.to_numeric, errors="coerce"
                )
                # calculate t_ref_count
                melt_csv_df = melt_csv_df.assign(
                    t_ref_count=melt_csv_df["t_depth"] - melt_csv_df["t_alt_count"]
                )
                # calculate t_alt_freq
                melt_csv_df = melt_csv_df.assign(
                    t_alt_freq=(
                        melt_csv_df["t_alt_count"] / melt_csv_df["t_depth"]
                    ).round(4)
                )
                # drop Evidence columns
                melt_csv_df.drop(columns=["Evidence"], inplace=True)
                # add additional columns
                melt_csv_df["Entrez_Gene_Id"] = 0
                melt_csv_df["Center"] = "mskcc.org"
                melt_csv_df["NCBI_Build"] = "GRCh37"
                melt_csv_df["Tumor_Seq_Allele1"] = melt_csv_df["Reference_Allele"]
                melt_csv_df["Strand"] = ""
                melt_csv_df["Consequence"] = ""
                melt_csv_df["dbSNP_RS"] = ""
                melt_csv_df["dbSNP_Val_Status"] = ""
                melt_csv_df["Match_Norm_Seq_Allele1"] = ""
                melt_csv_df["Match_Norm_Seq_Allele2"] = ""
                melt_csv_df["Tumor_Validation_Allele1"] = ""
                melt_csv_df["Tumor_Validation_Allele2"] = ""
                melt_csv_df["Match_Norm_Validation_Allele1"] = ""
                melt_csv_df["Match_Norm_Validation_Allele2"] = ""
                melt_csv_df["Verification_Status"] = ""
                melt_csv_df["Validation_Status"] = ""
                melt_csv_df["Mutation_Status"] = ""
                melt_csv_df["Sequencing_Phase"] = ""
                melt_csv_df["Sequence_Source"] = ""
                melt_csv_df["Validation_Method"] = ""
                melt_csv_df["Score"] = ""
                melt_csv_df["BAM_File"] = ""
                melt_csv_df["Sequencer"] = ""
                melt_csv_df["n_ref_count"] = ""
                melt_csv_df["n_alt_count"] = ""
                melt_csv_df["HGVSc"] = ""
                melt_csv_df["HGVSp"] = ""
                melt_csv_df["Transcript_ID"] = ""
                melt_csv_df["RefSeq"] = ""
                melt_csv_df["Protein_position"] = ""
                melt_csv_df["Codons"] = ""
                melt_csv_df = melt_csv_df.reindex(
                    columns=[
                        "Hugo_Symbol",
                        "Entrez_Gene_Id",
                        "Center",
                        "NCBI_Build",
                        "Chromosome",
                        "Start_Position",
                        "End_Position",
                        "Strand",
                        "Consequence",
                        "Variant_Classification",
                        "Variant_Type",
                        "Reference_Allele",
                        "Tumor_Seq_Allele1",
                        "Tumor_Seq_Allele2",
                        "dbSNP_RS",
                        "dbSNP_Val_Status",
                        "Tumor_Sample_Barcode",
                        "Matched_Norm_Sample_Barcode",
                        "Match_Norm_Seq_Allele1",
                        "Match_Norm_Seq_Allele2",
                        "Tumor_Validation_Allele1",
                        "Tumor_Validation_Allele2",
                        "Match_Norm_Validation_Allele1",
                        "Match_Norm_Validation_Allele2",
                        "Verification_Status",
                        "Validation_Status",
                        "Mutation_Status",
                        "Sequencing_Phase",
                        "Sequence_Source",
                        "Validation_Method",
                        "Score",
                        "BAM_File",
                        "Sequencer",
                        "t_depth",
                        "t_ref_count",
                        "t_alt_count",
                        "t_alt_freq",
                        "n_ref_count",
                        "n_alt_count",
                        "HGVSc",
                        "HGVSp",
                        "HGVSp_Short",
                        "Transcript_ID",
                        "RefSeq",
                        "Protein_position",
                        "Codons",
                        "Hotspot",
                        "DMP",
                        "CH",
                        "call_confidence",
                        "ExAC_AF",
                    ]
                )
                final_df = final_df.append(melt_csv_df, ignore_index=True)
            else:
                continue
        else:
            typer.secho(f"{csv_file} file does not exists", fg=typer.colors.BRIGHT_RED)
            raise typer.Abort()
    # write final_df to tsv
    typer.secho(
        f"Done processing the CSV file writing output to {output_file_prefix} in txt and excel format",
        fg=typer.colors.GREEN,
    )
    final_df.to_csv(f"{output_file_prefix}.maf", index=False, sep="\t")
    final_df.to_excel(f"{output_file_prefix}.xlsx", index=False)


if __name__ == "__main__":
    typer.run(main)
